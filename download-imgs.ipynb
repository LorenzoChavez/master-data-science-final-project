{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       photo                                                url\n",
      "0  000000001  http://s3.amazonaws.com/media.modcloth/images/...\n",
      "1  000000002  http://s3.amazonaws.com/media.modcloth/images/...\n",
      "2  000000003  http://s3.amazonaws.com/media.modcloth/images/...\n",
      "3  000000004  http://s3.amazonaws.com/media.modcloth/images/...\n",
      "4  000000005  http://media1.modcloth.com/community_outfit_im...\n",
      "(424840, 2)\n",
      "(424840,)\n",
      "(424840,)\n"
     ]
    }
   ],
   "source": [
    "# Download urls from www.tamaraberg.com/street2shop/wheretobuyit/photos.tar\n",
    "file_path = \"C:/Users/heret/Desktop/street2shop/photos.txt\"\n",
    "photos_file = pd.read_table(file_path, header=None)\n",
    "\n",
    "photos_file = photos_file[0].str.split(pat=\",\", n=1, expand=True)\n",
    "photos_file.columns = [\"photo\", \"url\"]\n",
    "\n",
    "print(photos_file.head())\n",
    "print(photos_file.shape)\n",
    "print(photos_file[\"photo\"].unique().shape)\n",
    "print(photos_file[\"url\"].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zappos.com             74353\n",
      "amazon.com             63982\n",
      "therealreal.com        55488\n",
      "neimanmarcus.com       28454\n",
      "media.com              23819\n",
      "nordstromimage.com     23434\n",
      "modcloth.com           18435\n",
      "targetimg1.com         17098\n",
      "forever21.com          11390\n",
      "macys.com               9619\n",
      "bloomingdales.com       7258\n",
      "urbanoutfitters.com     6545\n",
      "scene7.com              6255\n",
      "kohls.com               3516\n",
      "anthropologie.com       1942\n",
      "amazonaws.com           1922\n",
      "gap.com                 1874\n",
      "jcrew.com               1664\n",
      "express.com              476\n",
      "Name: 0, dtype: int64\n",
      "357524 images\n"
     ]
    }
   ],
   "source": [
    "# Top url domains\n",
    "url_domains = photos_file[\"url\"].str.extract(r'(\\w*.com)')\n",
    "print(url_domains[0].value_counts().sort_values(ascending=False))\n",
    "print(url_domains[0].value_counts().sort_values(ascending=False).sum(), \"images\") #not all but most included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_extraction_2(df):\n",
    "    urls = df[\"url\"].tolist()\n",
    "    photo_ids = df[\"photo\"].tolist()\n",
    "    img_path = \"C:/Users/heret/Desktop/street2shop/photos/\"\n",
    "    \n",
    "    for url, photo_id in zip(urls, photo_ids):\n",
    "        req.urlretrieve(url, str(img_path + photo_id.lstrip(\"0\") + \".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_n = 5119 #beware photos ids start at 1 not at 0 as python indexes. ie. start_n = 5216 will download from 5217\n",
    "finish_n = 20000 #ie. finish_n = 5218 will download until 5219 included\n",
    "split_urls = photos_file.loc[start_n:finish_n]\n",
    "#split_urls = photos_file.sort_index(ascending=False).loc[start_n:finish_n] #starting from end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image_extraction_2(split_urls) #started at 19:21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download labels from http://www.tamaraberg.com/street2shop/wheretobuyit/meta.zip\n",
    "retrieval_bags = pd.read_json(\"C:/Users/heret/Desktop/street2shop/meta/json/retrieval_bags.json\")\n",
    "test_pairs_bags = pd.read_json(\"C:/Users/heret/Desktop/street2shop/meta/json/test_pairs_bags.json\")\n",
    "train_pairs_bags = pd.read_json(\"C:/Users/heret/Desktop/street2shop/meta/json/train_pairs_bags.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retrieval_bags.shape)\n",
    "print(retrieval_bags.head())\n",
    "print(retrieval_bags[\"product\"].unique().shape)\n",
    "print(retrieval_bags[\"photo\"].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pairs_bags.shape)\n",
    "print(test_pairs_bags.columns)\n",
    "print(test_pairs_bags.head().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_pairs_bags.shape)\n",
    "print(train_pairs_bags.columns)\n",
    "print(train_pairs_bags.head().values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
