{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring model performance\n",
    "\n",
    "Once we have created a embeddings catalogue from which the most \"n\" similiar images are returned we need to measure how this process is performing.<br>\n",
    "This score will allow us to make improvements and meassure them, in order to find the best parameters and methods.\n",
    "\n",
    "For the evaluation we will only use the customer photos, and each one of them will be compared with the retrieved photos. As a result we will obtain a rank startint from the most similar photo. Then we will define a K parámeter that will set the top k images from the returned rank.\n",
    "\n",
    "For the evaluation we will use the following methods:\n",
    "   - Accuracy@K: total number of positive cases / total number of cases\n",
    "   - Recall@K: average of total number of positive cases for each \"id\" / total cases for each \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.applications.inception_v3 import InceptionV3 , preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "from scipy.spatial.distance import cdist\n",
    "# pip install h5py==2.8.0rc1 to disable the h5py warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv(\"./customer_df.csv\")\n",
    "retrieval_df = pd.read_csv(\"./retrieval_df.csv\")\n",
    "\n",
    "customer_df = customer_df[customer_df[\"category\"] == \"belts\"]\n",
    "retrieval_df = retrieval_df[retrieval_df[\"category\"] == \"belts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_aphanumeric(data):\n",
    "    \"\"\"This function sorts the data so that the dataframes, embedings and photos folder have the same order\n",
    "    1.jpg, 2.jpg, ... instead of 1.jpg, 10.jpg, 2.jpg ...\n",
    "    \"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the array representation of all images in the path specified in raw format for display and processed format for the NN\n",
    "def preprocess_img(dataset_path):\n",
    "    img_paths = sorted_aphanumeric(os.listdir(dataset_path))\n",
    "    img_paths = [os.path.join(dataset_path, img) for img in img_paths]\n",
    "    raw_imgs = [image.load_img(img, target_size=(250,250)) for img in img_paths]\n",
    "    proc_imgs = np.array([preprocess_input(np.expand_dims(image.img_to_array(img), axis=0)[0]) for img in raw_imgs])\n",
    "    return raw_imgs, proc_imgs\n",
    "\n",
    "#calculates the embeddings, write=True to get all the photos' embeddings to a csv, write=False for one-off customer queries\n",
    "def embeddings(img_arrays):\n",
    "    embeddings_img = [model.predict(np.expand_dims(img, axis=0)).flatten() for img in tqdm(img_arrays)]\n",
    "    embeddings_img = np.array(embeddings_img, np.float16) #float16 reduces decimal precision but saves disk space  \n",
    "    print(\"Writing to file\")\n",
    "    np.save(\"embeddings_belts_val.npy\", embeddings_img) #npy files save/load faster than csv when working with ndarrays\n",
    "\n",
    "def recommend_user(target_img, embs_catalogue, bbox=True, method=\"cosine\"):\n",
    "    if bbox == True:\n",
    "        raw_img = crop_image(target_img) #crops to bbox and resizes\n",
    "    else:\n",
    "        raw_img = plt.imread(target_img) #allows testing with an image without bboxes\n",
    "        raw_img = cv2.resize(raw_img, dsize=(250, 250), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    proc_img = preprocess_input(np.expand_dims(raw_img, axis=0)) #preprocess to NN format\n",
    "    embs_target = model.predict(proc_img).flatten() #extracts embedding\n",
    "    \n",
    "    distance = cdist(embs_catalogue, embs_target.reshape(1,-1), method) #run distances from user photo to catalogue\n",
    "    rank = np.argsort(distance.ravel()) #ranks by similarity, returns the indices that would sort the distance array\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the catalogue for category we wish to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catalogue_path = \"../photos_classified/belts/validation/retrieval/\"\n",
    "img_all_raw, img_all = preprocess_img(catalogue_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8349/8349 [04:36<00:00, 30.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings(img_all) #ONLY RUN THE FIRST TIME TO SAVE ALL EMBEDDINGS TO DISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "del img_all # not needed anymore. deletes the img_all array to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#using np to load all embeddings, watch out, this will initially fill up all ram\n",
    "embs_catalogue = np.load(\"./embeddings_belts_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#filters the customer data frame with the images from the validation folder only\n",
    "maskCustom = pd.Series(\n",
    "    [str(photo)+'.jpg' for photo in customer_df['photo']]).isin(os.listdir(\"../photos_classified/belts/validation/customer/\"))\n",
    "maskRetriev = pd.Series(\n",
    "    [str(photo)+'.jpg' for photo in retrieval_df['photo']]).isin(os.listdir(\"../photos_classified/belts/validation/retrieval/\"))\n",
    "\n",
    "customer_val_df = customer_df.reset_index(drop=True)[maskCustom].sort_values(by='photo', ascending=True)\n",
    "retrieval_val_df = retrieval_df.reset_index(drop=True)[maskRetriev].sort_values(by='photo', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(customer_df, retrieval_df, customer_path, retrieval_path, embs_catalogue, k, method=\"cosine\"):\n",
    "    \n",
    "    # Important: embedding has to have the same order as customer\n",
    "    # path to all photos\n",
    "    customer_photos = sorted_aphanumeric(os.listdir(customer_path))\n",
    "    validation_photos = sorted_aphanumeric(os.listdir(retrieval_path))\n",
    "    \n",
    "    all_positives = 0                                    #all positive cases to calculate accuracy\n",
    "    true_positives = np.empty(len(customer_photos))      #all true positives\n",
    "    actual_positives = np.empty(true_positives.size)     #true positives + false negatives\n",
    "    \n",
    "    for n, target_img in enumerate(customer_photos):\n",
    "        \n",
    "        # read and crop imgs\n",
    "        target_img = os.path.join(customer_path, target_img)\n",
    "        img_array = mpimg.imread(target_img) #target_img is the path to the jpg\n",
    "        photo_name = target_img.split(\"/\")[-1].split(\".\")[0]\n",
    "        image_customer = customer_df[customer_df[\"photo\"] == int(photo_name)]\n",
    "        if len(image_customer) > 1:\n",
    "            image_customer[\"fix_bbox\"] = image_customer[\"height\"] + image_customer[\"width\"] #aggs height and width, sorts them and picks the largest box\n",
    "            image_customer = image_customer.sort_values(by=\"fix_bbox\", ascending=False)[0:1] #this fixes a bug with some bboxes being 1px long\n",
    "\n",
    "        x0 = int(image_customer[\"left\"].values)\n",
    "        y0 = int(image_customer[\"top\"].values)\n",
    "        width = int(image_customer[\"width\"].values)\n",
    "        height = int(image_customer[\"height\"].values)\n",
    "\n",
    "        image_cropped = img_array[y0:y0+height , x0:x0+width, :]  \n",
    "        image_cropped = cv2.resize(image_cropped, dsize=(250, 250), interpolation=cv2.INTER_CUBIC) #cropped array\n",
    "\n",
    "        # calculate similarity rank\n",
    "        proc_img = preprocess_input(np.expand_dims(image_cropped, axis=0)) #keras preprocessing\n",
    "        embs_target = model.predict(proc_img).flatten()\n",
    "        distance = cdist(embs_catalogue, embs_target.reshape(1,-1), method) \n",
    "        rank = np.argsort(distance.ravel()) #index of retrieved photos in embeddings   \n",
    "        rank = retrieval_df.iloc[rank]['id'][:k].tolist()\n",
    "\n",
    "        image_id = image_customer['id'].tolist()[0]        \n",
    "        actual_positives[n] = len(retrieval_df[retrieval_df[\"id\"] == image_id])\n",
    "        \n",
    "#         print(n, rank[:10])\n",
    "        \n",
    "        if image_id in rank:\n",
    "            all_positives += 1\n",
    "            true_positives[n] = rank.count(image_id)\n",
    "        else:\n",
    "            true_positives[n] = 0\n",
    "    \n",
    "    accuracy = all_positives / len(customer_photos)\n",
    "    total_recall = (true_positives/actual_positives).mean()\n",
    "    \n",
    "    print(\"Positive cases:\", all_positives)\n",
    "    print(\"\\nAccuracy at {}: {:.2f}%\".format(k, accuracy*100))\n",
    "    print(\"Recall at {}: {:.2f}%\\n\".format(k, total_recall*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive cases: 21\n",
      "\n",
      "Accuracy at 20: 20.79%\n",
      "Recall at 20: 6.68%\n",
      "\n",
      "Wall time: 46.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "customer_validation_path = \"../photos_classified/belts/validation/customer/\"\n",
    "retrieval_validation_path = \"../photos_classified/belts/validation/retrieval/\"\n",
    "k = 20\n",
    "evaluate(customer_val_df, retrieval_val_df, customer_validation_path, retrieval_validation_path, embs_catalogue, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
