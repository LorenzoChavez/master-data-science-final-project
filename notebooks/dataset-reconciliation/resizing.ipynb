{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing images\n",
    "\n",
    "In order to make the dataset more manageable we size down the retrieval images to having width 300 and preserving the original aspect ratio, the customer images will remain the original size since cropping will be applied at a later stage before feeding them to a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating customer and retrieval dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files are separated into 3 classes: retrieval, train and test. Each of these classes have a json for each of the 11 clothing categories.  The function below merges all categories json files under the 3 classes, then train and test are also merged so we can do a custom data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels = \"./street2shop/meta/json\"\n",
    "def format_labels(path_labels, shop_images=False):\n",
    "    \n",
    "    json_files = os.listdir(path_labels)\n",
    "    json_files = [os.path.join(path_labels, file) for file in json_files] #reading in all json files\n",
    "    if shop_images==False:\n",
    "        all_files = [file for file in json_files if \"retrieval\" in file]\n",
    "    else:\n",
    "        all_files = [file for file in json_files if (\"train\" in file) | (\"test\" in file)]\n",
    "    \n",
    "    files_df = pd.DataFrame()\n",
    "    for file in all_files:\n",
    "        files_df = files_df.append(pd.read_json(file))\n",
    "    \n",
    "    category_files = [file.split(\"_\")[-1].split(\".json\")[0] for file in all_files]\n",
    "    print(\"Categories: \", category_files)\n",
    "\n",
    "    category_nrows = [pd.read_json(file).shape[0] for file in all_files]\n",
    "    print(\"Categories number of rows: \", category_nrows)\n",
    "    \n",
    "    files_df[\"category\"] = \"\"\n",
    "    for n, category in enumerate(category_files):\n",
    "        if n == 0:\n",
    "            files_df[\"category\"].iloc[0:category_nrows[0]] = category\n",
    "        index_0 = sum(category_nrows[:n])\n",
    "        index_1 = sum(category_nrows[:n+1])\n",
    "        files_df[\"category\"].iloc[index_0:index_1] = category\n",
    "    files_df = files_df.reset_index(drop=True)\n",
    "    \n",
    "    files_df[\"id\"] = files_df[\"product\"].astype(str) + \"_\" + files_df[\"category\"] #creating key for pair matching\n",
    "    \n",
    "    if shop_images == True:\n",
    "        files_df[\"bbox\"] = files_df[\"bbox\"].apply(lambda x: {k:v for k, v in sorted(x.items())}) #fixes missalignment in label order\n",
    "        files_df[\"bbox\"] = files_df[\"bbox\"].apply(lambda x: \"\".join(map(lambda x: str(x) + \",\", list(x.values()))))\n",
    "\n",
    "        bboxes = files_df[\"bbox\"].str.split(\",\",expand=True).drop(columns=[4])\n",
    "        bboxes.columns=([\"height\", \"left\", \"top\", \"width\"])\n",
    "        files_df = pd.concat([files_df,bboxes], axis=1).drop(columns=[\"bbox\"])\n",
    "        return files_df\n",
    "    return files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:  ['bags', 'belts', 'dresses', 'eyewear', 'footwear', 'hats', 'leggings', 'outerwear', 'pants', 'skirts', 'tops', 'bags', 'belts', 'dresses', 'eyewear', 'footwear', 'hats', 'leggings', 'outerwear', 'pants', 'skirts', 'tops']\n",
      "Categories number of rows:  [174, 89, 3292, 138, 2178, 86, 517, 666, 130, 604, 763, 579, 235, 12875, 358, 6486, 400, 1641, 1945, 600, 3337, 2173]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heret\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "customer_df = format_labels(path_labels, shop_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = customer_df[\"photo\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing\n",
    "~ 5h runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(dataset_path, output_path, customer_list, width=300):\n",
    "    \"\"\"Resizing fixed to width 300 and same aspect ratio due to having high variability in current img size.\n",
    "    Resizing only applies to retrieval images.\"\"\"\n",
    "    \n",
    "    all_paths = os.listdir(dataset_path)\n",
    "    for n, img_ in enumerate(tqdm(all_paths)):\n",
    "        try:\n",
    "            img_path = os.path.join(dataset_path, img_)\n",
    "            img_object = Image.open(img_path)\n",
    "            img_object = img_object.convert(\"RGB\") #exception with transparent channel, see https://stackoverflow.com/questions/48248405/cannot-write-mode-rgba-as-jpeg\n",
    "            if int(img_.split(\".\")[0]) not in customer_list: #checking if image is not from customer and resizing\n",
    "                width_percent = (width/float(img_object.size[0]))\n",
    "                height_size = int((float(img_object.size[1])*float(width_percent)))\n",
    "                img_object = img_object.resize((width,height_size), Image.ANTIALIAS)\n",
    "            output_img = os.path.join(output_path, img_)\n",
    "            img_object.save(output_img)\n",
    "\n",
    "        except OSError: #corrupted images will break it\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "image_resize(\"./../photos\", \"./../photos_resized\", customer_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
